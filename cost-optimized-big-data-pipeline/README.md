# Cost Optimized Big Data Pipeline

This project demonstrates a **cost-optimized data pipeline** using **Databricks** and **PySpark**.

## Project Overview
- Generates a synthetic dataset of 100,000 orders.
- Filters and transforms the data.
- Computes aggregated summaries (total and average per category).
- Full dataset saved as CSV/Excel for reporting.

## Steps
1. Data generation
2. Transformation / filtering
3. Aggregation
4. Export to CSV/Excel

## Tools
Databricks, PySpark, Pandas, Excel/CSV
